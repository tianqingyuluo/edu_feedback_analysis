{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# 设置中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: 读取数据\n",
    "# -------------------------------\n",
    "df = pd.read_csv('../../data/intermediate/初步清洗_比赛数据_2.csv',\n",
    "                 sep=',', engine='python', encoding='utf-8')\n",
    "\n",
    "# 去除制表符\n",
    "df = df.map(lambda x: x.strip('\\t') if isinstance(x, str) else x)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: 定义原始特征列（sx_cols）\n",
    "# -------------------------------\n",
    "sx_cols = [\n",
    "    '课前预学','课堂参与','课后复习','延伸阅读',\n",
    "    '完成作业时间','自习时间','课外阅读时间','网络课程时间',\n",
    "    '实验科研时间','社团活动时间','竞赛活动时间','其他学习时间',\n",
    "    '同学合作','参与科研团队','参与学科竞赛','学习同学方法','师生交流频度'\n",
    "]\n",
    "\n",
    "# 转为 float\n",
    "df[sx_cols] = df[sx_cols].astype(float)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -------------------------------\n",
    "# Step 3: 数据标准化\n",
    "# -------------------------------\n",
    "X = df[sx_cols].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ],
   "id": "cf6b779488ac4911",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -------------------------------\n",
    "# Step 4: PCA 降维\n",
    "# -------------------------------\n",
    "# 保留前 6 个主成分（可调整 n_components）\n",
    "pca = PCA(n_components=7, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"PCA 解释的累计方差比例:\", np.sum(pca.explained_variance_ratio_))"
   ],
   "id": "cd2eff6079df0e53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 输出每个主成分解释的方差比例\n",
    "explained_ratios = pca.explained_variance_ratio_\n",
    "cum_var = np.cumsum(explained_ratios)\n",
    "\n",
    "print(\"PCA 各主成分方差贡献率：\")\n",
    "for i, ratio in enumerate(explained_ratios, start=1):\n",
    "    print(f\"主成分 {i}: {ratio:.3f}, 累计: {cum_var[i-1]:.3f}\")\n",
    "\n",
    "\n",
    "#可视化方差贡献率\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(range(1, len(explained_ratios)+1), explained_ratios, alpha=0.7, align='center', label='单个主成分方差贡献率')\n",
    "plt.step(range(1, len(cum_var)+1), cum_var, where='mid', label='累计方差贡献率', color='red')\n",
    "\n",
    "plt.xlabel('主成分序号')\n",
    "plt.ylabel('方差解释比例')\n",
    "plt.title('PCA 主成分方差贡献率')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "e1d8c0197cef076f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 获取每个主成分的特征向量（载荷）\n",
    "loadings = pca.components_\n",
    "\n",
    "# 转换成 DataFrame，更直观\n",
    "loading_df = pd.DataFrame(loadings.T,\n",
    "                          columns=[f'PC{i+1}' for i in range(loadings.shape[0])],\n",
    "                          index=['完成作业时间','自习时间','课外阅读时间','网络课程时间','其他学习时间',\n",
    "                                 '课前预学','课堂参与','课后复习','延伸阅读','学习同学方法',\n",
    "                                 '实验科研时间','参与科研团队','参与学科竞赛','竞赛活动时间',\n",
    "                                 '同学合作','社团活动时间','师生交流频度'])\n",
    "\n",
    "print(\"PCA 载荷矩阵：\")\n",
    "print(loading_df.round(3))\n"
   ],
   "id": "116666fd88bedd00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -------------------------------\n",
    "# Step 5: 确定聚类数 K (肘部法 + 轮廓系数)\n",
    "# -------------------------------\n",
    "wcss = []\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_pca)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_pca, kmeans.labels_))\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(2,10), wcss, 'o-', label='WCSS')\n",
    "plt.xlabel('聚类数 K')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('肘部法')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(2,10), silhouette_scores, 'o-', label='轮廓系数')\n",
    "plt.xlabel('聚类数 K')\n",
    "plt.ylabel('轮廓系数')\n",
    "plt.title('轮廓系数')\n",
    "plt.show()\n"
   ],
   "id": "aef0361aea7e23ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -------------------------------\n",
    "# Step 6: 聚类建模 (KMeans, 假设 4 类)\n",
    "# -------------------------------\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "df['cluster'] = kmeans.fit_predict(X_pca)\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Step 7: 映射画像标签 (可人工命名)\n",
    "# -------------------------------\n",
    "cluster_mapping = {\n",
    "    0: '科研学霸型',\n",
    "    1: '社团活跃型',\n",
    "    2: '学业挣扎型',\n",
    "    3: '自主学习型'\n",
    "}\n",
    "df['student_persona'] = df['cluster'].map(cluster_mapping)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 8: 统计分析\n",
    "# -------------------------------\n",
    "print(\"各画像人数分布：\")\n",
    "print(df['student_persona'].value_counts())\n",
    "\n",
    "persona_means = df.groupby('student_persona')[sx_cols].mean()\n",
    "print(\"\\n各画像特征均值：\")\n",
    "print(persona_means)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 9: 可视化\n",
    "# -------------------------------\n",
    "# (1) 各画像人数柱状图\n",
    "sns.countplot(x='student_persona', data=df,\n",
    "              order=df['student_persona'].value_counts().index)\n",
    "plt.title(\"各画像人数分布\")\n",
    "plt.show()"
   ],
   "id": "8e64104535df47a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# (2) PCA 前两维度可视化聚类效果\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=df['student_persona'], palette=\"Set2\")\n",
    "plt.title(\"PCA降维后的聚类分布（前2主成分）\")\n",
    "plt.xlabel(\"主成分1\")\n",
    "plt.ylabel(\"主成分2\")\n",
    "plt.legend()\n",
    "plt.show() "
   ],
   "id": "6fe1222b2de994fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# 创建标签编码器\n",
    "le = LabelEncoder()\n",
    "# 将字符串标签转换为数值\n",
    "numeric_labels = le.fit_transform(df['student_persona'])\n",
    "\n",
    "# (2) PCA 三维聚类结果可视化\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 绘制三维散点图 - 使用数值标签\n",
    "scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2],\n",
    "                     c=numeric_labels, cmap=\"Set2\", s=50, alpha=0.8)\n",
    "\n",
    "# 设置标题和坐标轴标签\n",
    "ax.set_title(\"PCA降维 - 聚类分布（前三主成分）\", fontsize=14)\n",
    "ax.set_xlabel(\"主成分1\", fontsize=12)\n",
    "ax.set_ylabel(\"主成分2\", fontsize=12)\n",
    "ax.set_zlabel(\"主成分3\", fontsize=12)\n",
    "\n",
    "# 添加图例 - 需要手动创建图例\n",
    "legend_labels = le.classes_\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor=plt.cm.Set2(i/len(legend_labels)),\n",
    "                      markersize=10) for i in range(len(legend_labels))]\n",
    "ax.legend(handles, legend_labels, title=\"学生画像\", loc=\"upper right\", fontsize=10)\n",
    "\n",
    "# 显示图形\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "9f77e3e48d3b9c42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Step 10: 用 GMM + BIC 客观选择簇数，并进行“软聚类”\n",
    "# =========================\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "Ks = range(2, 10)\n",
    "bics = []\n",
    "gmms = []\n",
    "\n",
    "# 建议在“标准化后的原始特征空间 X_scaled”上拟合GMM\n",
    "for k in Ks:\n",
    "    gmm = GaussianMixture(n_components=k, covariance_type='full', random_state=42)\n",
    "    gmm.fit(X_scaled)\n",
    "    bics.append(gmm.bic(X_scaled))\n",
    "    gmms.append(gmm)\n",
    "\n",
    "best_k = Ks[int(np.argmin(bics))]\n",
    "best_gmm = gmms[int(np.argmin(bics))]\n",
    "\n",
    "print(\"GMM-BIC 选择的最佳簇数:\", best_k)\n",
    "\n",
    "df['gmm_cluster'] = best_gmm.predict(X_scaled)\n",
    "proba = best_gmm.predict_proba(X_scaled)  # 每个样本对各簇的后验概率\n",
    "df['gmm_confidence'] = proba.max(axis=1)\n",
    "\n",
    "# 标记不确定样本（可调整阈值）\n",
    "uncertain_thr = 0.55\n",
    "df['gmm_uncertain'] = (df['gmm_confidence'] < uncertain_thr)\n",
    "\n",
    "# =========================\n",
    "# Step 11: 用“客观自动命名”给GMM簇命名（基于z值的过度/不足）\n",
    "# =========================\n",
    "Z2 = pd.DataFrame(X_scaled, columns=sx_cols)\n",
    "Z2['gmm_cluster'] = df['gmm_cluster']\n",
    "gmm_cluster_z = Z2.groupby('gmm_cluster')[sx_cols].mean()\n",
    "gmm_auto_names = gmm_cluster_z.apply(build_auto_label, axis=1).to_dict()\n",
    "df['gmm_persona'] = df['gmm_cluster'].map(gmm_auto_names)\n",
    "\n",
    "print(\"GMM 自动标签：\", gmm_auto_names)\n",
    "\n",
    "# 对不确定样本追加说明（可选）\n",
    "df.loc[df['gmm_uncertain'], 'gmm_persona'] = df.loc[df['gmm_uncertain'], 'gmm_persona'] + \"（混合型/不确定）\"\n",
    "\n",
    "# =========================\n",
    "# Step 12: 画像“特征签名”表（每簇z值排序）\n",
    "# =========================\n",
    "def cluster_signature(z_df, topn=5):\n",
    "    sig = {}\n",
    "    for c, row in z_df.iterrows():\n",
    "        order = row.sort_values(ascending=False)\n",
    "        sig[c] = {\n",
    "            'top_pos': order.head(topn).round(2).to_dict(),\n",
    "            'top_neg': order.tail(topn).round(2).to_dict()\n",
    "        }\n",
    "    return sig\n",
    "\n",
    "print(\"KMeans 簇签名：\", cluster_signature(cluster_z, topn=5))\n",
    "print(\"GMM 簇签名：\", cluster_signature(gmm_cluster_z, topn=5))\n",
    "\n",
    "# =========================\n",
    "# Step 13: 可解释规则（用决策树解释 GMM 簇）\n",
    "# =========================\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "\n",
    "tree_gmm = DecisionTreeClassifier(max_depth=3, min_samples_leaf=30, random_state=42)\n",
    "tree_gmm.fit(X_scaled, df['gmm_cluster'])\n",
    "print(export_text(tree_gmm, feature_names=sx_cols))\n",
    "\n",
    "# =========================\n",
    "# Step 14: 特征重要性（置换重要度，避免树模型固有偏好）\n",
    "# =========================\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "perm = permutation_importance(tree_gmm, X_scaled, df['gmm_cluster'],\n",
    "                              n_repeats=20, random_state=42, n_jobs=-1)\n",
    "imp = pd.Series(perm.importances_mean, index=sx_cols).sort_values(ascending=False)\n",
    "print(\"\\n置换重要度：\\n\", imp.round(4))\n",
    "\n",
    "# =========================\n",
    "# Step 15: 个体层面的“与簇均值距离”和“样本轮廓系数”\n",
    "# =========================\n",
    "from sklearn.metrics import silhouette_samples, pairwise_distances\n",
    "\n",
    "# a) 轮廓系数（基于你原先KMeans的标签）\n",
    "df['km_silhouette'] = silhouette_samples(X_pca, df['cluster'])\n",
    "\n",
    "# b) 与各簇中心（标准化空间）距离，衡量“典型性”\n",
    "#    先把KMeans中心从PCA -> 标准化空间\n",
    "km_centers_scaled = pca.inverse_transform(kmeans.cluster_centers_)\n",
    "D = pairwise_distances(X_scaled, km_centers_scaled)  # 形状: [n_samples, n_clusters]\n",
    "df['km_center_dist'] = D.min(axis=1)  # 与所属中心的最小距离\n",
    "\n",
    "# 标记“非典型个体”（既远离中心又轮廓系数低）\n",
    "df['km_atypical'] = (df['km_center_dist'] > np.percentile(df['km_center_dist'], 80)) & (df['km_silhouette'] < 0.1)\n",
    "\n",
    "# =========================\n",
    "# Step 16: 稳定性简单检测（KMeans重启一致性）\n",
    "# =========================\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "def km_labels(seed):\n",
    "    return KMeans(n_clusters=kmeans.n_clusters, random_state=seed, n_init=10).fit_predict(X_pca)\n",
    "\n",
    "labels_ref = df['cluster'].values\n",
    "aris = []\n",
    "for seed in range(43, 53):\n",
    "    aris.append(adjusted_rand_score(labels_ref, km_labels(seed)))\n",
    "print(\"KMeans 重复拟合 ARI（越高越稳定）:\", np.round(aris, 3), \"平均:\", np.mean(aris).round(3))\n"
   ],
   "id": "463533d5fbfb29e8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
